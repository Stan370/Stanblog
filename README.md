# stanBlog
[个人技术博客blog，学习路线！](https://stan370.github.io/)
# Questions

#### 浏览器中输入url到页面展示过程

  用户输入url，例如http://[www.baidu.com](http://www.baidu.com/)。其中http为协议，[www.baidu.com](http://www.baidu.com/)为网络地址，及指出需要的资源在那台计算机上。一般网络地址可以为域名或IP地址，此处为域名。使用域名是为了方便记忆，但是为了让计算机理解这个地址还需要把它解析为IP地址。

2.应用层DNS解析域名

  客户端先检查本地是否有对应的IP地址，若找到则返回响应的IP地址。若没找到则请求上级DNS服务器，直至找到或到根节点。

3.应用层客户端发送HTTP请求

HTTP请求包括请求报头和请求主体两个部分，其中请求报头包含了至关重要的信息，包括请求的方法（GET / POST）、目标url、遵循的协议（http / https / ftp…），返回的信息是否需要缓存，以及客户端是否发送cookie等。

4.传输层TCP传输报文

  位于传输层的TCP协议为传输报文提供可靠的字节流服务。它为了方便传输，将大块的数据分割成以报文段为单位的数据包进行管理，并为它们编号，方便服务器接收时能准确地还原报文信息。TCP协议通过“三次握手”等方法保证传输的安全可靠。

 “三次握手”的过程是，发送端先发送一个带有SYN（synchronize）标志的数据包给接收端，在一定的延迟时间内等待接收的回复。接收端收到数据包后，传回一个带有SYN/ACK标志的数据包以示传达确认信息。接收方收到后再发送一个带有ACK标志的数据包给接收端以示握手成功。在这个过程中，如果发送端在规定延迟时间内没有收到回复则默认接收方没有收到请求，而再次发送，直到收到回复为止。

[![TCP](https://images0.cnblogs.com/blog/622045/201507/020946560314133.png)](http://images0.cnblogs.com/blog/622045/201507/020946557039933.png) 

5.网络层IP协议查询MAC地址

  IP协议的作用是把TCP分割好的各种数据包传送给接收方。而要保证确实能传到接收方还需要接收方的MAC地址，也就是物理地址。IP地址和MAC地址是一一对应的关系，一个网络设备的IP地址可以更换，但是MAC地址一般是固定不变的。**ARP协议可以将IP地址解析成对应的MAC地址**。当通信的双方不在同一个局域网时，需要多次中转才能到达最终的目标，在中转的过程中需要通过下一个中转站的MAC地址来搜索下一个中转目标。

6.数据到达数据链路层

  在找到对方的MAC地址后，就将数据发送到数据链路层传输。这时，客户端发送请求的阶段结束

7.服务器接收数据

  接收端的服务器在链路层接收到数据包，再层层向上直到应用层。这过程中包括在运输层通过TCP协议讲分段的数据包重新组成原来的HTTP请求报文。

8.服务器响应请求

  服务接收到客户端发送的HTTP请求后，查找客户端请求的资源，并返回响应报文，响应报文中包括一个重要的信息——状态码。状态码由三位数字组成，其中比较常见的是200 OK表示请求成功。301表示永久重定向，即请求的资源已经永久转移到新的位置。在返回301状态码的同时，响应报文也会附带重定向的url，客户端接收到后将http请求的url做相应的改变再重新发送。404 not found 表示客户端请求的资源找不到。

9. 服务器返回相应文件

  请求成功后，服务器会返回相应的HTML文件。接下来就到了页面的渲染阶段了。

### 二、页面渲染

  现代浏览器渲染页面的过程是这样的：解析HTML以构建DOM树 –> 构建渲染树 –> 布局渲染树 –> 绘制渲染树。

  DOM树是由HTML文件中的标签排列组成，渲染树是在DOM树中加入CSS或HTML中的style样式而形成。渲染树只包含需要显示在页面中的DOM元素，像<head>元素或display属性值为none的元素都不在渲染树中。

  在浏览器还没接收到完整的HTML文件时，它就开始渲染页面了，在遇到外部链入的脚本标签或样式标签或图片时，会再次发送HTTP请求重复上述的步骤。在收到CSS文件后会对已经渲染的页面重新渲染，加入它们应有的样式，图片文件加载完立刻显示在相应位置。在这一过程中可能会触发页面的重绘或重排。




**TCP 如何保证可靠性？**

TCP主要提供了检验和、序列号/确认应答、超时重传、最大消息长度、滑动窗口控制等方法实现了可靠性传输。

Mysql**表格设计**？

平衡范式与冗余(效率优先；往往牺牲范式)拒绝3B(拒绝大[sql语句](https://so.csdn.net/so/search?q=sql语句&spm=1001.2101.3001.7020)：big sql、拒绝大事务：big transaction、拒绝大批量：big batch);

先建立索引或者分区，然后再查询

**判断循环链表** 原链表反向啊，构造双向链表，快慢指针

**Restful规范**

**Features**

1、每一个URI代表1种资源；

2、客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源；

3、通过操作资源的表现形式来操作资源；

4、资源的表现形式是XML或者HTML；

5、客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。

在 Spring 构建 RESTful Web 服务的方法中，HTTP 请求由控制器处理。这些组件由 @RestController 注释标识，下面清单中显示的 GreetingController（来自 src/main/java/com/example/restservice/GreetingController.java）通过返回 Greeting 的新实例来处理 /greeting 的 GET 请求班级：

```java
@RestController  
public class TestController {  
    @Autowired(required = false)  
    DogMapper dogMapper;  
    @GetMapping("dogs")  
    public List<Dog> getDogs()  
    {  
        return  dogMapper.getAllDog();  
    }  
```

缺点

- 比如操作方式繁琐，RESTful API通常根据GET、POST、PUT、DELETE 来区分操作资源的动作，而HTTP Method 本身不可直接见，是隐藏的，而如果将动作放到URL的path上反而清晰可见，更利于团队的理解和交流。
- 并且有些浏览器对GET,POST之外的请求支持不太友好，还需要特殊额外的处理。
- 过分强调资源，而实际业务API可能有各种需求比较复杂，单单使用资源的增删改查可能并不能有效满足使用需求，强行使用RESTful风格API只会增加开发难度和成本。

## 高并发解决

假如有1秒钟有1万个请求，我们的apache服务器的连接数500，处理业务的时间为100ms，4台服务器的连接数1秒内能处理500*4/0.1=2万(QPS)，完全满足这个要求了，但实际情况是随着请求数的增加，机器处于高负荷的状态，CPU切换次数增大会严重影响处理时长，很有可能由100ms变成500ms甚至更长，此时1秒钟处理的连接数为500*4/0.5=4000，这就会导致大量的请求阻塞.时间越长阻塞越大。根据用户的行为特征，越是阻塞就越会去点击请求这样就会雪上加霜，最终拖垮服务进程

二、解决方案

1、前后端分离

前端采用静态html页面，这样就不需要进行视图渲染了，减少性能开销。一些静态页面、css样式、js可以采用CDN加速。前后端分离可以独立发布，前端有问题，可以直接改好发布而不需要重启服务端，一些大型项目启动服务端会耗费很长时间，如果此时访问量很大的话就会出现阻塞现象。

2、服务端接口处理速度要快

1）引入缓存

就比如上面的场景，优化代码缩短处理时间也是可以解决的。像这种高并发的情况，能不查数据库就不查数据库，因为数据库的连接也是有限的，比如mysql连接数好像在500左右，而且连接数据库也是耗时间的。这种情况可以想办法将数据放入缓存，比如redis，redis连接数在5万左右且查询速度远比数据库要快，会节省大量查询时间。还有些数据是基础数据一直都不会变的，可以加载到本地缓存比如谷歌的guava

2）尽量使用乐观锁

悲观锁是互斥的，遇到加锁状态必须等待，这会增加阻塞的概率。而且高并发的情况下，有些线程可能永远都拿不到锁，对用户体验是非常差的。

乐观锁可以解决这个问题，不过乐观锁有时候会更新不到数据，此时就会去重试，增加系统开销，但相对悲观锁来说会好很多。可以使用redis的watch功能(redis乐观锁)

3）拆分功能-微服务概念

比如一个系统里有会员信息、商品信息、交易信息，那么我们可以拆成3个微服务，图片、文件用专门的服务器存储，每个应用单独部署，且每个微服务部署集群，每个微服务有自己的数据库。这样就会用户请求跟数据交互都分流了。

这个会增加成本，不过既要性能高又要成本低不太现实，看实际情况了。如果高并发长时间才会搞一次，可以采取灵活部署的办法，平常可以一台服务器部署多个微服务，等活动开始的时候增加机器分开部署

4）削峰

削峰主要通过消息来处理，比如rabbitMq、kafka,这种行为属于偷懒行为，对于实时性要求不高的场景是可以的。一般QPS为1万以上的推荐kafka，实时性要求非常高的用rabbitmq。

5）重启与过载保护

假如服务进程挂了，这样的高并发情况下，重启几乎是无效的，重启就会立马崩溃掉，此时需要加一个服务网关做限流控制，还有用到redis的需要预热操作

3、从用户行为上做控制

1）页面上不让用户重复点击，点击后置灰，别小看这个功能，可以减少50%的无效请求。

2）防作弊，有些用户可以通过技术手段绕过上面的限制，这样就需要在服务端做限制了。比如限流，配置一个用户一定时间内最多访问多少请求，可以用redis存储用户的请求次数，最好用watch功能，避免用户同时操作。有些黄牛可能有多个用户，那么就需要针对IP做限制了，比如增加验证码，当然也可以直接对IP做限流，不过可能会误伤部分用户。

3）有些黄牛会模拟真实场景，比如12306抢票，这样的话只能通过大数据分析了，根据用户行为筛选出哪些账户是僵尸账户，平常不动，高峰期就活跃了，这样可以有针对性的对这些用户做限制操作

4、考虑事务问题

高并发的情况下如果不做控制很容易出现数据错乱的问题，解决这个问题需要数据同步。

大致思路有：

1、悲观锁

比如synchronized,lock,redis分布式锁，悲观锁容易造成阻塞

2、同步队列

请求全部进入一个同步队列里，然后一个个操作，跟悲观锁类似，也容易造成阻塞

3、乐观锁

数据库加版本号，每次更新操作需要带版本号进行幂等操作。也可以用redis的watch功能，乐观锁操作会有很多无效操作，增加重试开销，但相对引起阻塞的问题这点性能开销还是可以接受的，所以高并发情况下最好还是用乐观锁

互联网正在高速发展，使用互联网服务的用户越多，高并发的场景也变得越来越多。电商秒杀和抢购，是两个比较典型的互联网高并发场景。虽然我们解决问题的具体技术方案可能千差万别，但是遇到的挑战却是相似的，因此解决问题的思路也异曲同工。

个人整理并发解决方案。

a.应用层面：读写分离、缓存、队列、集群、令牌、系统拆分、隔离、系统升级（可水平扩容方向）。

b.时间换空间：降低单次请求时间，这样在单位时间内系统并发就会提升。

c.空间换时间：拉长整体处理业务时间，换取后台系统容量空间。



# 操作系统

<img src="https://pic.leetcode-cn.com/1642125846-FXGHTw-20210216234120.png" alt="img" style="zoom: 67%;" />

并发Concurrent：无论上一个开始执行的任务是否完成，当前任务都可以开始执行 （也就是说，A B 顺序执行的话，A 一定会比 B 先完成，而并发执行则不一定。） 与可以一起执行的并行（parallel）相对的是不可以一起执行的串行（serial）

综上，并发与并行并不是互斥的概念，只是前者关注的是任务的抽象调度、后者关注的是任务的实际执行。而它们又是相关的，比如**并行一定会允许并发**。 所以题目中的例子： 

单核 CPU 多任务：并发（不必等上一个任务完成才开始下一个任务）、串行（只有一个实际执行任务的 CPU 核）

 多线程：并发、串行（所有线程都在同一个核上执行）；并发、并行（不同线程在不同的核上执行）

**进程与线程之间的关系与区别：**进程是资源分配的基本单位。线程是系统调度的基本单位

① 进程 **包含** 多个线程② 进程间 **不共用** 变量与资源；线程间 **共用** 变量与资源

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC

、

**什么是虚拟内存**

**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的[内存空间](https://www.zhihu.com/search?q=内存空间&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"82746153"})）**。这样会更加有效地管理内存并减少出错。

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**

**分页系统映射**

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。



## 进程同步

1. 临界区
   对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

HTML

// entry section
// critical section;
// exit section

2. 同步与互斥
   同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
   互斥：多个进程在同一时刻只有一个进程能进入临界区。
3. 信号量
   信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。
down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。

**互斥锁**

1严格轮换法    加入锁变量                 2 Peterson算法           进程0出临界区后进程1才会离开忙等待

C

typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
使用信号量实现生产者-消费者问题

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

## **进程间通信**

1. 管道
   管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

  只支持半双工通信（单向交替传输）；
  只能在父子进程或者兄弟进程中使用。


2. FIFO
   也称为命名管道，去除了管道只能在父子进程中使用的限制。

3. 消息队列
   相比于 FIFO，消息队列具有以下优点：

消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

4. 信号量
   它是一个计数器，用于为多个进程提供对共享数据对象的访问。

5. 共享存储
   允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

6. Socket
   与其它通信机制不同的是，它可用于不同机器间的进程通信。

3.共享

1）空分复用技术

空分复用技术的原理就是<u>把内存作为高速缓存来使用，只用来保存最频繁使用的部分程序，而把程序的大部分放在磁盘上</u>。这种机制需要快速的映像内存地址，以便把程序生成的地址转换为有关字节在内存中的物理地址。这种映像由 CPU 中的一个部件，称为存储器管理单元（Memory Management Unit，MMU）来完成

2）时分复用技术

多个进程能在同一个 CPU 上并发执行就是因为使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。显然，如果失去了并发性，一个时间段内系统中只能运行一道程序，那也就失去了实现虚拟性的意义了。因此，**没有并发性，就谈不上虚拟性**

4.异步是指：在多道程序环境下，允许多个程序并发执行，但**由于资源有限，进程的执行不是一贯到底的， 而是走走停停，以不可预知的速度向前推进**，这就是进程的异步性。

- 进程管理

- 内存管理

  虚拟内存技术，把内存作为高速缓存来使用，只用来保存最频繁使用的部分程序，而把程序的大部分放在磁盘上。

  那么内存管理做的事情大概就是：

  把使用频繁的部分程序放入内存
  当内存满的时候，替换掉内存中的某些部分

  

- 文件系统管理

- I/O 设备管理

内核态和用户态

内核kernel是程序，它需要运行，就必须被分配 CPU。因此，CPU 上会运行两种程序，一种是操作系统的内核程序（也称为系统程序），一种是应用程序。前者完成系统任务，后者实现应用任务。两者之间有控制和被控制的关系，前者有权管理和分配资源，而后者只能向系统申请使用资源。



# **设计模式**

**1. **   创建型模式，这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。共五种：**工厂方法模式、抽象工厂模式**、**单例模式**、建造者模式、**原型模式。**

**2、** 结构型模式，这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。

**3、** 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。

**简单工厂，工厂方法，[抽象工厂]**都属于设计模式中的创建型模式。其主要功能都是帮助我们把对象的实例化部分抽取了出来，优化了系统的架构，并且增强了系统的扩展性。

★工厂模式中，重要的是工厂类，而不是产品类。产品类可以是多种形式，多层继承或者是单个类都是可以的。但要明确的，工厂模式的接口只会返回一种类型的实例，这是在设计产品类的时候需要注意的，最好是有父类或者共同实现的接口。

★使用工厂模式，返回的实例一定是工厂创建的，而不是从其他对象中获取的。

★工厂模式返回的实例可以不是新创建的，返回由工厂创建好的实例也是可以的。

区别

简单工厂 ： 用来生产同一等级结构中的任意产品。一台咖啡机就可以理解为一个工厂模式，你只需要按下想喝的咖啡品类的按钮（摩卡或拿铁），它就会给你生产一杯相应的咖啡，你不需要管它内部的具体实现，只要告诉它你的需求即可。（对于增加新的产品，无能为力）

工厂方法 ：用来生产同一等级结构中的固定产品。（支持增加任意产品）  
抽象工厂 ：用来生产不同产品族的全部产品。（对于增加新的产品，无能为力；支持增加产品族）  

不想喝咖啡了想喝啤酒，这个时候如果直接修改简单工厂里面的代码，这种做法不但不够优雅，也不符合软件设计的“开闭原则”,这时直接继承抽象class override方法

**单例模式**（Singleton Pattern）是 Java 中最简单的设计模式之一，提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。

**优点：**

- 1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。
- 2、避免对资源的多重占用（比如写文件操作）。

**缺点：**没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。

**使用场景：**

- 1、要求生产唯一序列号。
- 2、WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。
- 3、创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。

**注意事项：**getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。



适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能













**加密**

由于加密和解密需要两个不同的密钥，故被称为非对称加密；不同于加密和解密都使用同一个密钥的[对称加密](https://zh.wikipedia.org/wiki/对称加密)。公钥可以公开，可任意向外发布；私钥不可以公开，必须由用户自行严格秘密保管，绝不透过任何途径向任何人提供，也不会透露给被信任的要通信的另一方。

# Database

**数据库的4种隔离级别：**

原子性（Atomicity）：原子性是指一个事务中的操作，要么全部成功，要么全部失败，如果失败，就回滚到事务开始前的状态。

一致性（Consistency）：一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。那转账举栗子，A账户和B账户之间相互转账，无论如何操作，A、B账户的总金额都必须是不变的。

隔离性（Isolation）：隔离性是当多个用户 并发的 访问数据库时，如果操作同一张表，数据库则为每一个用户都开启一个事务，且事务之间互不干扰，也就是说事务之间的并发是隔离的。再举个栗子，现有两个并发的事务T1和T2，T1要么在T2开始前执行，要么在T2结束后执行，如果T1先执行，那T2就在T1结束后在执行。关于数据的隔离性级别，将在后文讲到。

持久性（Durability）：持久性就是指如果事务一旦被提交，数据库中数据的改变就是永久性的，即使断电或者宕机的情况下，也不会丢失提交的事务操作。

[并发三个特性 ：原子性、可见性、有序性](https://www.cnblogs.com/guanghe/p/9206635.html)

## 分布式

CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得。

- 一致性（C）：对某个指定的客户端来说，读操作能返回最新的写操作结果

- 可用性（A）：非故障节点在合理的时间返回合理的响应

- 分区容错性（P）：分区容错性是指当网络出现分区（两个节点之间无法连通）之后，系统能否继续履行职责

- 以电商网站为例，会员登录、个人设置、个人订单、购物车、搜索用AP，因为这些数据短时间内不一致不影响使用；后台的商品管理就需要CP，避免商品数量的不一致；支付功能需要CA，保证支付功能的安全稳定

  BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。

MQ（Message Queue）[消息队列](https://baike.baidu.com/item/消息队列/4751675)，是基础数据结构中“先进先出”的一种数据结构。一般用来解决应用解耦，异步消息，流量削峰等问题，实现高性能，高可用，可伸缩和最终一致性架构

# 爬虫

re匹配

正则表达式 .* 就是单个字符匹配任意次，即贪婪匹配。 表达式 .*? 是满足条件的情况只匹配一次，即最小匹配.

# Internet protocol

WWW是Internet上的一个应用功能。不是network.事实上，WWW（万维网）是一个基于互联网的全球、交互式、动态、多平台、分布式和图形化DDBMS信息系统，它只是一种基于互联网的网络服务。

Protocol defines format,order of messages was sent, received among network entities ,and  actions taken on transmission,receipt

192.168.1.1属于[IP地址](https://baike.baidu.com/item/IP地址)的[C类地址](https://baike.baidu.com/item/C类地址)，属于保留IP，专门用于[路由器](https://baike.baidu.com/item/路由器/108294)[设置](https://baike.baidu.com/item/设置/9987085)。一般来讲这个地址的密码根据路由器厂商的设置会有所不同，但一般会是：[用户名](https://baike.baidu.com/item/用户名/7241132)（区分大小写）：[admin](https://baike.baidu.com/item/admin/273663) [密码](https://baike.baidu.com/item/密码/65553)：admin如果您已经修改了这个密码，请输入您修改后的密码。如果不是您修改的，可以重设路由器[管理员](https://baike.baidu.com/item/管理员/5710966)来获取这个密码，或者重置路由器设置来恢复设备初始密码。

### OSI

MAC∈datalink LAN层

常见的网络编程中的问题主要是怎么定位网络上的一台主机或多台主机，另一个是定位后如何进行数据的传输。对于前者，在网络层中主要负责网络主机的定位，数据传输的路由，由IP地址可以唯一地确定Internet上的一台主机。对于后者，在传输层则提供面向应用的可靠（tcp）的或非可靠（UDP）的数据传输机制。 

对于客户端/服务器（C/S）结构。 即通信双方一方作为服务器等待客户提出请求并予以响应。客户则在需要服务时向服务器提出申请。服务器一般作为守护进程始终运行，监听网络端口，一旦有客户请求，就会启动一个服务进程来响应该客户，同时自己继续监听服务端口，使后来的客户也能及时得到服务。

对于浏览器/服务器（B/S）结构。 客户则在需要服务时向服务器进行请求。服务器响应后及时返回，不需要实时监听端口。

二者的区别，取决于怎么看他们，**如果使用浏览器，浏览器就是指“客户端”，**“client/server” 和 “browser/server”两种体系结构没有真正的区别，没法比较



<img src="C:\Users\Stan\AppData\Roaming\Typora\typora-user-images\image-20210920175427765.png" alt="image-20210920175427765" style="zoom:50%;" />

#### HTTP TCP IP

HTTP规定了每段数据以什么形式表达才是能够被另外一台计算机理解。而TCP所要规定的是数据应该怎么传输才能稳定且高效的传递与计算机之间。

HTTPS

SSL

> SSL(Secure Sockets Layer 安全套接层)是为网络通信提供安全及数据完整性的一种安全协议。SSL 是 “Secure Sockets Layer” 的缩写，中文意思为“安全套接层”，而 TLS 则是标准化之后的 SSL。

TLS

> 安全传输层协议（TLS：Transport Layer Security）用于在两个通信应用程序之间提供保密性和数据完整性。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake），是更新、更安全的SSL版本。 HTTPS use TLS1.3

先非对称加密，最后使用会话密钥时对称加密

<img src="C:\Users\Stan\AppData\Roaming\Typora\typora-user-images\image-20220316150839289.png" alt="image-20220316150839289" style="zoom: 80%;" />

**HTTP**:

200OK  请求成功  400 bad request

Idempotent幂等性概念：幂等通俗来说是指不管进行多少次重复操作，都是实现相同的结果。

2.REST请求中哪些是幂等操作
GET，PUT，DELETE都是幂等操作，而POST不是，以下进行分析：

首先GET请求很好理解，对资源做查询多次，此实现的结果都是一样的。    PUT请求的幂等性可以这样理解，将A修改为B

> 

##### **HTTP的核心概念**

除了HTTP存在于应用层之外，该协议还有5个特点。

1. HTTP的标准建立在将两台计算机视为不同的角色：客户端和服务器。客户端会向服务器传送不同的请求(request)，而服务器会对应每个请求给出回应(response)。**无连接**

2. HTTP属于**无状态协议(Stateless)**。这表示每一个请求之间是没有相关性的。在该协议的规则中**服务器是不会记录任何客户端操作**，每一次请求都是独立的。（记录用户浏览行为会通过其他技术实现）

3. 客户端的请求被定义在几个动词意义范围内。最长用到的是GET和POST，其他动词还包括DELETE, HEAD等等。

   ### [GET和POST两种http请求方法的区别]

   GET和POST是HTTP请求的两种基本方法, HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。**GET请求没有body，只有url，请求数据放在url的querystring中；POST请求的数据在body中“。但这种情况仅限于浏览器发请求的场景。**GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。 

   **GET**

   “读取“一个资源。**比如Get到一个html文件。反复读取不应该对访问的数据有副作用。比如”GET一下，用户就下单了，返回订单已受理“，这是不可接受的。没有副作用被称为“幂等“（Idempotent)。**

   因为GET因为是读取，就可以对GET请求的数据做缓存。这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），或者做到server端（用Etag，至少可以减少带宽消耗）

   - 千万不要用GET方法传送密码等敏感信息！（发出的数据会在浏览器地址栏中显示出来）

   **POST**

   在页面里<form> 标签会定义一个表单。**点击其中的submit元素会发出一个POST请求让服务器做一件事。这件事往往是有副作用的，不幂等的。**

   不幂等也就意味着不能随意多次执行。因此也就不能缓存。比如通过POST下一个单，服务器创建了新的订单，然后返回订单成功的界面。这个页面不能被缓存。试想一下，如果POST请求被浏览器缓存了，那么下单请求就可以不向服务器发请求，而直接返回本地缓存的“下单成功界面”，却又没有真的在服务器下单。那是一件多么滑稽的事情。

   因为POST可能有副作用，所以浏览器实现为不能把POST请求保存为书签。想想，如果点一下书签就下一个单，是不是很恐怖？。

   **POST方法比GET方法更健壮、更安全，而且POST方法对数据大小没有限制。**

   

4. 服务器的回应被定义在几个状态码之间：5开头表示服务器错误，4开头表示客户端错误，3开头表示需要做进一步处理，2开头表示成功，1开头表示在请求被接受处理的同时提供的额外信息。

5. 不管是客户端的请求信息还是服务器的回应，双方都拥有一块头部信息(Header)。头部信息是自定义，其用途在于传递额外信息（浏览器信息、请求的内容类型、相应的语言）。

##### 持久 or pipeline 连接

　**持久连接：**使用同一个TCP连接发送和接受 **多个** http请求/应答；http1.1 
　　**非持久连接：**一个TCP连接只能发送和接受 **一个** http请求/应答；

stateful contains stateless filter, which is the most flexible but cost more.

`队头阻塞`是一个专有名词，不仅仅在 HTTP 有，交换器等其他地方也都涉及到了这个问题。实际上引起这个问题的根本原因是使用了`队列`这种数据结构。协议规定， 对于同一个 tcp 连接，所有的 **http1.0** 请求放入队列中，只有前一个`请求的响应`收到了，才能发送下一个请求，这个时候就发生了阻塞，并且这个阻塞主要发生在客户端。

<img src="C:\Users\Stan\AppData\Roaming\Typora\typora-user-images\image-20220121153947934.png" alt="image-20220121153947934" style="zoom:80%;" />报文结构

###### HTTP2.0

相比 HTTP/1.x，HTTP/2 在底层传输做了很大的改动和优化：

（1） HTTP/2 采用二进制格式传输数据，而非 HTTP/1.x 的文本格式。二进制格式在协议的解析和优化扩展上带来更多的优势和可能。

（2） HTTP/2 对消息头采用 HPACK 进行压缩传输，能够节省消息头占用的网络的流量。而 HTTP/1.x 每次请求，都会携带大量冗余头信息，浪费了很多带宽资源。头压缩能够很好的解决该问题。

（3） 多路复用，直白的说就是所有的请求都是通过一个TCP 连接并发完成。HTTP/1.x 虽然通过 pipeline 也能并发请求，但是多个请求之间的响应会被阻塞的，所以 pipeline 至今也没有被普及应用，而 HTTP/2 做到了真正的并发请求。同时，流还支持优先级和流量控制。

（4） Server Push：服务端能够更快的把资源推送给客户端。例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 再发送这些请求。当客户端需要的时候，它已经在客户端了。


为了解决`HTTP/1.1`中的服务端队首阻塞，`HTTP/2`采用了`二进制分帧` 和 `多路复用` 等方法。 **多路复用 (Multiplexing)****

**多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。**



**pipeline连接**

　　HTTP/1.1的新特性，允许在**持久连接**上可选地使用请求管道。在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向服务器时，第二条和第三条请求也可以开始发送了。**在髙时延网络条件下，这样做可以降低网络的环回时间，提高性能。** 

**管道化连接有如下几条限制：**

1. 客户端必须确认是**持久连接**才能使用管道；




TCP/IP 意味着 TCP 和 IP 在一起协同工作。TCP 负责应用软件（比如您的浏览器）和网络软件之间的通信。

Internet 的**传输层**有两个主要协议，互为补充。无连接的是 UDP，它除了给应用程序发送数据包功能并允许它们在所需的层次上架构自己的协议之外，几乎没有做什么特别的事情。面向连接的是 [TCP](https://baike.baidu.com/item/TCP/33012)，该协议几乎做了所有的事情。

***使用无连接协议可以很方便地支持一对多和多对一通信，而面向连接协议通常都需要多个独立的连接才能做到。但更重要的是，无连接协议是构建面向连接协议的基础**。TCP/IP 是基于一个４层的协议栈，如下图所示：*

IP 负责计算机之间的通信。TCP 负责将数据分割并装入 IP 包，然后在它们到达的时候重新组合它们。IP 负责将包发送至接受者。

## Transport layer

https://blog.csdn.net/m0_46156900/article/details/113809699传输层概述、传输层服务、多路复用和解复用、无连接传输 UDP

#### DEMUX

**connectionless**: 主机接收到**UDP** segment (dest port dest IP)

connection **oriented**: 

- **服务器能够在一个TCP端口上同时支持多个TCP套接字：**
   每个套接字由其四元组标识（有不同的源IP和源PORT）
- ** Web服务器对每个连接客户端有不同的套接字**
   非持久对每个请求有不同的套接字

“服务器能够根据源IP地址和源端口号来区分来自不同客户机的报文段。
但是套接字与进程之间并非总是有着一一对应的关系。
事实上，Web服务器通常一个服务进程可以为每个新的客户机连接创建一个具有新连接套接字的线程。
显然，对于这样的服务器，在任意给定的时间内都可能有很多套接字(具有不同的标识)连接到同一个进程。”

##### rdt3.0：

具有比特差错和分组丢失的信道

**新的假设：****下层信道可能会丢失分组（数据或ACK）**(好比之前说的路由器队列排满了，新来的就被drop掉)

- ** 会死锁**
- ** 机制还不够处理这种状况：**
  • ** rdt3.0可以工作，但链路容量比较大的情况下，性能很差**
  ** 链路容量比较大，一次发一个PDU 的不能够充分利用链路的传输能力**

<img src="https://img-blog.csdnimg.cn/20210216113823842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

### TCP

HTTP 协议是一种**面向连接的无状态**的请求-应答协议。

在HTTP的规范内，两台计算机的交互被视为request和response的传递。**而在实际的TCP操作中，信息传递会比单纯的传递request和response要复杂。通过TCP建立的通讯往往需要计算机之间多次的交换信息才能完成一次request或response。**

TCP的传输数据的核心是在于将数据分为若干段并将每段数据按顺序标记。标记后的顺序可以以不同的顺序被另一方接收并集成回完整的数据。计算机对每一段数据的成功接收都会做出相应，确保所有数据的完整性。

TCP在传递数据时依赖于实现定义好的几个标记（Flags）去向另一方表态传达数据和连接的状态：

* F : FIN - 结束; 结束会话																			
* S : SYN - 同步; 表示开始会话请求
* R : RST - 复位;中断一个连接                P : PUSH - 推送; 数据包立即发送
* A : ACK - 应答        U : URG - 紧急           E : ECE - 显式拥塞提醒回应
* W : CWR - 拥塞窗口减少
